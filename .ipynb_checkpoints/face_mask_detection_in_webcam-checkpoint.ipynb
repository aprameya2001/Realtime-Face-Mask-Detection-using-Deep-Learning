{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face mask detection through webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (15, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define all parameters\n",
    "def define_parameters():\n",
    "    \n",
    "    print(\"DEFINING PARAMETERS...\")\n",
    "    \n",
    "    global prototxt_path, weights_path, MIN_CONFIDENCE, path_to_model\n",
    "\n",
    "    # Files needed for face detection\n",
    "    prototxt_path = './Pretrained_face_detection_model_opencv/deploy.prototxt.txt'\n",
    "    weights_path = './Pretrained_face_detection_model_opencv/res10_300x300_ssd_iter_140000.caffemodel'\n",
    "\n",
    "    # Minimum probability to filter weak detections\n",
    "    MIN_CONFIDENCE = 0.5\n",
    "\n",
    "    # Trained mask detector model\n",
    "    path_to_model = 'mask_detector_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all models\n",
    "\n",
    "def load_models():\n",
    "    print(\"LOADING MODELS...\")\n",
    "    \n",
    "    global prototxt_path, weights_path\n",
    "    \n",
    "    # Load the face detector model\n",
    "    # This face detection model is a pretrained model and is supported by opencv\n",
    "    face_detection_dnn = cv2.dnn.readNet(prototxt_path, weights_path)\n",
    "\n",
    "    # Loading the face mask detection model that was created by us\n",
    "    mask_detection_model = load_model(path_to_model)\n",
    "    mask_detection_model.summary()\n",
    "    \n",
    "    return face_detection_dnn, mask_detection_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect all faces in the image using the pretrained model\n",
    "\n",
    "def detect_faces(image, face_detection_dnn):    \n",
    "    blob = cv2.dnn.blobFromImage(image, 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "    # we resize to 300Ã—300 pixels and perform mean subtraction.\n",
    "\n",
    "    # BLOB stands for Binary Large OBject and refers to a group of connected pixels in a binary image. \n",
    "    # The term \"Large\" indicates that only objects of a certain size are of interest \n",
    "    # and that the other \"small\" binary objects are usually noise.\n",
    "    \n",
    "    # pass the blob through the network and obtain the face detections\n",
    "\n",
    "    face_detection_dnn.setInput(blob)\n",
    "    face_detections = face_detection_dnn.forward()\n",
    "\n",
    "    # Now we have all the detected faces and we know the location of each detected face\n",
    "    # We will consider a face to be 'detected' if its confidence is greater than our minimum confidence\n",
    "    \n",
    "    return face_detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect face masks\n",
    "\n",
    "def detect_mask(frame, face_detection_dnn, mask_detection_model):\n",
    "    height = frame.shape[0]\n",
    "    width = frame.shape[1]\n",
    "    \n",
    "    face_detections = detect_faces(frame, face_detection_dnn)\n",
    "    \n",
    "    faces = []        # stores detected faces if any\n",
    "    locations = []    # stores the locations of the detected faces\n",
    "    predictions = []  # stores the mask/ no mask predictions\n",
    "    \n",
    "    # Iterate through all the face detections\n",
    "\n",
    "    for i in range(face_detections.shape[2]):\n",
    "        # Confidence or probability of currenct detection\n",
    "        confidence = face_detections[0, 0, i, 2]\n",
    "\n",
    "        # Detections with confidence higher than our threshold are only considered\n",
    "        if confidence > MIN_CONFIDENCE:\n",
    "            # Computing boundaries of the bounding box of the detected face\n",
    "            detected_rectangle = face_detections[0, 0, i, 3:7] * np.array([width, height, width, height])\n",
    "            (startX, startY, endX, endY) = detected_rectangle.astype(\"int\")\n",
    "\n",
    "            # Ensuring that the position of the detected face are within the boundaries of the image\n",
    "            startX = max(0, startX)\n",
    "            startY = max(0, startY)\n",
    "            endX = min(endX, width-1)\n",
    "            endY = min(endY, height-1)\n",
    "\n",
    "            # Extracting and pre- processing the detected face\n",
    "            face_img = frame[startY:endY, startX:endX]\n",
    "            face_img = cv2.cvtColor(face_img, cv2.COLOR_BGR2RGB)\n",
    "            face_img = cv2.resize(face_img, (224, 224))\n",
    "            face_img = img_to_array(face_img)\n",
    "            face_img = preprocess_input(face_img)\n",
    "            \n",
    "            faces.append(face_img)\n",
    "            locations.append((startX, startY, endX, endY))\n",
    "            \n",
    "            \n",
    "    # Making a batch prediction on the detected images\n",
    "    \n",
    "    if len(faces)>0:\n",
    "        faces = np.array(faces, dtype = 'float32')\n",
    "        predictions = mask_detection_model.predict(faces, batch_size = 32)\n",
    "        \n",
    "    return (locations, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the webcam and detect face masks in each of the frames\n",
    "\n",
    "def start_facemask_detection_in_webcam(face_detection_dnn, mask_detection_model):\n",
    "    print('STARTING THE VIDEO STREAM...')\n",
    "\n",
    "    vid = cv2.VideoCapture(0)\n",
    "    vid.set(3, 1280)\n",
    "    vid.set(4, 720)\n",
    "    time.sleep(2.0)\n",
    "    \n",
    "\n",
    "    # loop over the frames from the video stream\n",
    "    while vid.isOpened():\n",
    "        # resize each frame to have a maximum width of 400 pixels\n",
    "        ret, frame = vid.read()\n",
    "        \n",
    "        # detect faces in the frame and determine if they are wearing a face mask or not\n",
    "        (locations, predictions) = detect_mask(frame, face_detection_dnn, mask_detection_model)\n",
    "        \n",
    "        for (location, prediction) in zip(locations, predictions):\n",
    "            (startX, startY, endX, endY) = location\n",
    "            (mask, withoutMask) = prediction\n",
    "            \n",
    "            # Output\n",
    "            if mask > withoutMask:\n",
    "                label = 'Mask'\n",
    "                colour = (0,255,0)\n",
    "            else:\n",
    "                label = 'No Mask'\n",
    "                colour = (0,0,255)\n",
    "            \n",
    "            label1 = label \n",
    "            label2 = 'Probability: {:.2f}%'.format(max(mask, withoutMask)*100)\n",
    "            \n",
    "            # Displaying output and rectangle\n",
    "            cv2.putText(frame, label1, (startX, startY - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, colour, 4)\n",
    "            cv2.rectangle(frame, (startX, startY), (endX, endY), colour, 3)\n",
    "            cv2.putText(frame, label2, (startX, endY+30), cv2.FONT_HERSHEY_SIMPLEX, 1, colour, 4)\n",
    "            cv2.putText(frame, 'Press Q to exit', (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0), 4)\n",
    "            \n",
    "        # Displaying the output frame\n",
    "        cv2.imshow('Face Mask Detection', frame)\n",
    "        \n",
    "        # Break if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "            \n",
    "    # Destroy all frames and close the videostream\n",
    "    vid.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEFINING PARAMETERS...\n",
      "LOADING MODELS...\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenetv2_1.00_224 (Model) (None, 7, 7, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                81984     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 2,340,098\n",
      "Trainable params: 82,114\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n",
      "STARTING THE VIDEO STREAM...\n"
     ]
    }
   ],
   "source": [
    "define_parameters()\n",
    "face_detection_dnn, mask_detection_model = load_models()\n",
    "start_facemask_detection_in_webcam(face_detection_dnn, mask_detection_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
